### Test
"
右下角master改成main
先勾进行提交 随便写个注释
然后推送 main:origin->main
传不上去 就终端 git push -u origin main
再不行 就 git push -f origin main

Test Fix ban
"git config --global --unset https.proxy
在dwd层解决Hbase维度表上传kafka时报错，主要是因为我们的配置出现了问题，在我们的realtime-common 的子模块中
分别有base 层，bean,common,functions,utils,我的common文件夹中的constant,
由于是copy的隔壁组的项目，我的检查不够自习，漏掉了
public static final String HBASE_NAMESPACE = "gmall2024";
public static final String PROCESS_DATABASE = "gmall2024_config";
这两个是关羽HBAse的配置信息
在Hbase中需要创建命名空间，然后在执行我们的dwd中的app,主要是因为我们的dwd不会自动在Hbase中创建命名空间
这个报错一开始不知道为什么，导致浪费掉了大量时间


我们对学过的知识需要即使的复习，
1 spark on hive 和 hive on spark 的区别
spark on hive ： hive只是我们的存储角色，spark 负责sql 解析优化，执行。可以理解为spark通过spark sql 使用 hive
语句操作hive 表，底层运行的还是spark RDD，
人话，读hive的数据，用spark执行，（使用它人多）

hive on spark :
人话：hive 既要作为存储，又负责sql的解析优化，spark 负责执行。但是麻烦，需要重新编译我的spark 和 jar包

数据采集：
主要来源：1 前台埋点产生的日志数据，业务系统产生的业务数据

flinkcdc 底层实现的原理
1.flnk 流式处理框架
2，数据库日志解析k
