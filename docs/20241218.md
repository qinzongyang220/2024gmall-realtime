####     实时项目

​          我们最近做了一个实时的医疗项目，基于Flink做的

发过程中sql,api都用的(具体:dws层进行一些数据关联写入doris数据库,api:在ads层生成指标写了接口进行可视化)

ODS 层：对数据源进行原样存储，作为数据仓库的原始数据备份，主要采集自业务数据库的变更数据，通过 Kafka topic_db 主题进行存储。

DIM 层：存储维度模型的维度表，基于 HBase 存储，通过 Flink CDC 读取 MySQL 配置表信息，实现维度表的动态创建和数据写入。

DWD 层：存储维度模型的事实表，数据来源于 ODS 层经过清洗、转换和筛选后的业务数据，按照业务过程进行分类存储，表名遵循 dwd_数据域_表名的命名规范。

DWS 层：基于 DWD 层数据进行轻度聚合，参考指标体系设计，存储不同统计粒度和业务过程的汇总数据，表名规范为 dws_数据域_统计粒度_业务过程_统计周期（window），数据最终写入 Doris 数据库，为数据分析提供支持。


----------------------
### 拉链表

就是记录历史，记录一个事物从开始，一直到当前的所有变化的信息，

我们可以使用这张表拿到最新的当天的最新数据以及之气那的历史数据。

既能满足反应数据的历史状态，又可以最大限度地节省存储空间




-------------------------------------------
#### Hive分区和分桶

分区是文件夹（PARTITIONED BY） 可以将数据按照特定的列值进行划分

分区通常基于以下几个因素：

- 时间：根据时间戳或日期将数据按照不同的时间段进行分区，例如按年、月、日等。
- 地理位置：根据地理信息将数据按照不同的地域进行分区，例如国家、城市等。
- 类别/类型：根据某个类别或类型属性将数据进行分类并进行相应的分区。

分桶是分文件（CLUSTERED BY`和`SORTED BY） 当数据量查询效率低的时候可以使用，

例如 ，时间可以按小时还分

-------------------------
#### Hive是怎么转成MapReduce程序的

其实就是hive的四个解析器

- 解析器（Parser）：将SQL语句转换为抽象语法树（AST），然后进一步转换为查询块（QB）。
- 编译器（Compiler）：将查询块（QB）编译为逻辑执行计划。
- 优化器（Optimizer）：对逻辑执行计划进行优化。
- 执行器（Executor）：将逻辑执行计划转换为可以运行的MapReduce作业。