# 自我介绍

面试官您好，我叫秦宗阳，在大数据行业有5年工作经验，比较擅长数据开发，主要一些离线的项目 实时的也有做 ，离弦项目有基于hive开发的,有的基于云产品开发的，实时项目主要基于flink开发的， 对于线上产品阿里的dataworks, dataplinl, 线下集群CDH CDP都能够 完成独立的搭建部署压测调优上线 开发语言主要使用java和python java主要用于写一些flinksql 做一些flink项目 pyhon主要用于爬虫，数据的清洗 脱敏等

我在数据分析与开发领域积累了丰富的经验。在数据分析方面，我熟练掌握多种数据分析工具和技术，如 SQL 用于高效的数据查询与管理，Excel 进行复杂的数据处理和可视化呈现，Python 及其数据分析库（如 Pandas、Numpy、Matplotlib 等）能深入挖掘数据价值，洞察数据背后的业务趋势和问题，为决策提供有力支持，曾通过数据分析帮助公司优化业务流程，提升了10% 的运营效率。

作为开发工程师，我精通多种编程语言，如 Java 和 C++，能够独立完成从需求分析、架构设计到代码编写与测试的全流程开发任务，具备良好的代码规范和调试能力，所开发的 [项目名称] 系统稳定运行，获得了团队和客户的高度认可。我相信自己的专业技能和积极的工作态度，能为团队带来显著的价值，期待在新的岗位上继续成长和贡献力量。
---------------------------------------------------------
#### Hive架构

hive架构包括几个核心组件

1，用户接口：

- **CLI**（Command Line Interface）：命令行接口，最常用的方式。
- **Web UI**：网页用户接口。
- **JDBC/ODBC**：允许使用标准的数据库连接方式，如Java数据库连接（JDBC）和开放数据库连接（ODBC）。

2，驱动器

- 解析器（Parser）：将SQL语句转换为抽象语法树（AST），然后进一步转换为查询块（QB）。
- 编译器（Compiler）：将查询块（QB）编译为逻辑执行计划。
- 优化器（Optimizer）：对逻辑执行计划进行优化。
- 执行器（Executor）：将逻辑执行计划转换为可以运行的MapReduce作业。

3，元数据存储

- 存储有关数据库结构和存储的表和分区的元数据信息。Hive元数据可以存储在关系数据库中，如MySQL、PostgreSQL等。

4.MapReduce/YARN

- Hive中的查询最终会转换为MapReduce作业在Hadoop集群上执行。在Hadoop 2.x及以后版本中，MapReduce运行在YARN（Yet Another Resource Negotiator）上。

5，hdfs

- Hive中的数据实际上是存储在HDFS上的。
---------------------------------------------------------------------
#### SQL优化

避免使用select *

使用union all 代替union

小表join大表

谓词下推

先聚合,在join减少扫描数据量 事实表join ,维度表可以先聚合在关联维度如果聚合条件是维度表字段  必须先关联

分区和分桶减少扫描数据量  分区(提高数据管理效率):分文件夹   分桶(优化数据处理和分析性能):分文件